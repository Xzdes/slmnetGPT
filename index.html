<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>slmnetGPT v2.0 - Финальная версия</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; background-color: #f0f2f5; color: #1c1e21; display: flex; flex-direction: column; align-items: center; padding: 20px; }
        .container { background-color: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); width: 100%; max-width: 800px; }
        h1, h2 { text-align: center; color: #1877f2; }
        button { background-color: #1877f2; color: white; border: none; padding: 10px 15px; border-radius: 6px; font-size: 16px; cursor: pointer; transition: background-color 0.2s; margin: 5px; }
        button:hover { background-color: #166fe5; }
        button:disabled { background-color: #a0bdf0; cursor: not-allowed; }
        textarea, input { width: calc(100% - 24px); padding: 10px; border: 1px solid #ddd; border-radius: 6px; font-size: 14px; font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace; margin-bottom: 10px; }
        pre { background-color: #f0f2f5; padding: 10px; border-radius: 6px; white-space: pre-wrap; word-wrap: break-word; font-size: 14px; margin-top: 5px; max-height: 200px; overflow-y: auto; }
        .controls { display: flex; justify-content: center; align-items: center; flex-wrap: wrap; }
        hr { border: none; border-top: 1px solid #ddd; margin: 25px 0; }
    </style>
</head>
<body>
    <div class="container">
        <h1>slmnetGPT v2.0</h1>
        <h2>Генеративная модель-трансформер в браузере</h2>

        <hr>
        <h3>Обучение</h3>
        <p>Модель будет обучаться на тексте ниже. Нажмите "Начать обучение", чтобы запустить процесс.</p>
        <textarea id="training-data" rows="12">
«Мой дядя самых честных правил,
Когда не в шутку занемог,
Он уважать себя заставил
И лучше выдумать не мог.
Его пример другим наука;
Но, боже мой, какая скука
С больным сидеть и день и ночь,
Не отходя ни шагу прочь!
Какое низкое коварство
Полуживого забавлять,
Ему подушки поправлять,
Печально подносить лекарство,
Вздыхать и думать про себя:
Когда же черт возьмет тебя!»

Так думал молодой повеса,
Летя в пыли на почтовых,
Всевышней волею Зевеса
Наследник всех своих родных.
        </textarea>
        <div class="controls">
            <button id="train-btn">Начать обучение</button>
        </div>
        <pre id="log-output">Лог обучения...</pre>
        
        <hr>
        <h3>Генерация текста</h3>
        <p>Введите начальную фразу (затравку) и нажмите "Сгенерировать".</p>
        <input id="prompt-input" type="text" value="Когда ">
        <div class="controls">
            <button id="generate-btn" disabled>Сгенерировать</button>
        </div>
        <pre id="generated-output">Здесь появится сгенерированный текст...</pre>
    </div>

    <script type="module">
        import slmnet from './slmnet/slmnet.js';

        const ui = {
            trainBtn: document.getElementById('train-btn'),
            generateBtn: document.getElementById('generate-btn'),
            logOutput: document.getElementById('log-output'),
            generatedOutput: document.getElementById('generated-output'),
            promptInput: document.getElementById('prompt-input'),
            trainingData: document.getElementById('training-data')
        };
        
        // --- Гиперпараметры для финальной, более мощной модели ---
        const config = {
            block_size: 64,      // Увеличенный контекст
            embedding_dim: 64,   // Увеличенный размер эмбеддингов ("глубина" нейрона)
            num_heads: 4,        // Количество "голов внимания"
            num_layers: 4,       // Увеличенное количество слоев трансформера ("глубина" сети)
            learning_rate: 0.001,
            train_steps: 6000     // Увеличенное время обучения
        };

        let model, tokenizer, optimizer;

        // --- Модель GPT ---
        class GPTModel extends slmnet.layers.Layer {
            constructor(vocab_size, config) {
                super();
                this.token_embedding = new slmnet.layers.Embedding(vocab_size, config.embedding_dim);
                this.position_embedding = new slmnet.layers.Embedding(config.block_size, config.embedding_dim);
                this.blocks = new slmnet.layers.Sequential(
                    Array.from({ length: config.num_layers }, () => new slmnet.layers.TransformerBlock(config.embedding_dim, config.num_heads))
                );
                this.final_ln = new slmnet.layers.LayerNorm(config.embedding_dim);
                this.output_head = new slmnet.layers.Dense(config.embedding_dim, vocab_size);
            }

            forward(idx) {
                const [_, seq_len] = idx.shape;
                const tok_emb = this.token_embedding.forward(idx);
                const pos_ids = new slmnet.Tensor(Float32Array.from({length: seq_len}, (_, i) => i), [1, seq_len]);
                const pos_emb = this.position_embedding.forward(pos_ids);
                let x = tok_emb.add(pos_emb);
                x = this.blocks.forward(x);
                x = this.final_ln.forward(x);
                return this.output_head.forward(x);
            }
        }
        
        // --- Вспомогательные функции ---
        function getBatch(encoded_text, block_size) {
            const start_index = Math.floor(Math.random() * (encoded_text.length - block_size - 1));
            const end_index = start_index + block_size;
            const x = encoded_text.slice(start_index, end_index);
            const y = encoded_text.slice(start_index + 1, end_index + 1);
            return {
                x: new slmnet.Tensor(x, [1, block_size]),
                y: new slmnet.Tensor(y, [y.length])
            };
        }
        
        function clip_grads(parameters, max_norm) {
            let total_norm_sq = 0;
            for (const p of parameters) {
                if (p.grad) {
                    for (const grad_val of p.grad.data) {
                        total_norm_sq += grad_val * grad_val;
                    }
                }
            }
            const total_norm = Math.sqrt(total_norm_sq);

            if (total_norm > max_norm) {
                const scale_factor = max_norm / total_norm;
                for (const p of parameters) {
                    if (p.grad) {
                        for (let i = 0; i < p.grad.data.length; i++) {
                            p.grad.data[i] *= scale_factor;
                        }
                    }
                }
            }
            return total_norm;
        }
        
        // --- Основные процессы ---
        async function trainingLoop() {
            ui.trainBtn.disabled = true;
            ui.generateBtn.disabled = true;
            ui.logOutput.textContent = "Инициализация...\n";
            console.clear();
            console.log("--- НАЧАЛО ФИНАЛЬНОЙ СЕССИИ ОБУЧЕНИЯ (Deep Model) ---");
            
            await new Promise(resolve => setTimeout(resolve, 10));

            const text = ui.trainingData.value;
            tokenizer = new slmnet.tokenizers.CharacterTokenizer(text);
            const encoded_text = tokenizer.encode(text);
            model = new GPTModel(tokenizer.vocab_size, config);
            optimizer = new slmnet.optimizers.Adam(model.parameters(), config.learning_rate);
            
            ui.logOutput.textContent += `Словарь: ${tokenizer.vocab_size} символов.\nНачинаю обучение (это может занять несколько минут)...\n`;
            await new Promise(resolve => setTimeout(resolve, 10));

            for (let i = 0; i < config.train_steps; i++) {
                optimizer.zero_grad();
                const {x, y} = getBatch(encoded_text, config.block_size);
                const logits = model.forward(x);
                const loss = slmnet.losses.cross_entropy_loss(logits, y);
                
                if (isNaN(loss.data[0])) {
                    ui.logOutput.textContent += `Шаг ${i}: Ошибка стала NaN. Обучение остановлено.\n`;
                    console.error(`Обучение остановлено на шаге ${i} из-за ошибки NaN.`);
                    break;
                }

                loss.backward();
                const grad_norm = clip_grads(model.parameters(), 1.0);
                optimizer.step();

                if (i % 100 === 0 || i === config.train_steps - 1) {
                    const loss_val = loss.data[0];
                    ui.logOutput.textContent += `Шаг ${i}: Ошибка = ${loss_val.toFixed(4)}\n`;
                    ui.logOutput.scrollTop = ui.logOutput.scrollHeight;
                    console.log(`Шаг ${i} | Ошибка: ${loss_val.toFixed(4)} | Норма градиента: ${grad_norm.toFixed(4)}`);
                    if (i % 500 === 0) {
                       await new Promise(resolve => setTimeout(resolve, 10));
                    }
                }
            }
            ui.logOutput.textContent += "Обучение завершено!\n";
            ui.trainBtn.disabled = false;
            ui.generateBtn.disabled = false;
        }

        function generate() {
            if (!model || !tokenizer) return;
            ui.generateBtn.disabled = true;
            ui.trainBtn.disabled = true;
            
            // Температура управляет "креативностью"
            // 0.1 = очень консервативно, 1.0 = очень случайно
            const temperature = 0.8; 
            const prompt_text = ui.promptInput.value;
            let context_ids = tokenizer.encode(prompt_text);
            const generated_ids = [];

            for(let i = 0; i < 300; i++) { // Генерируем больше символов
                const current_context_ids = context_ids.slice(-config.block_size);
                const context_tensor = new slmnet.Tensor(current_context_ids, [1, current_context_ids.length]);
                const logits_tensor = model.forward(context_tensor);
                
                const vocab_size = tokenizer.vocab_size;
                const last_step_logits_data = logits_tensor.data.slice((current_context_ids.length - 1) * vocab_size);
                
                // Применяем температуру для изменения распределения вероятностей
                for (let j = 0; j < last_step_logits_data.length; j++) {
                    last_step_logits_data[j] /= temperature;
                }

                const last_step_logits = new slmnet.Tensor(last_step_logits_data, [1, vocab_size]);
                const probs = slmnet.Ops.softmax(last_step_logits).data;

                // Сэмплируем следующий токен, а не просто берем самый вероятный
                const rand = Math.random();
                let cumulative_prob = 0;
                let next_id = 0;
                for (let j = 0; j < probs.length; j++) {
                    cumulative_prob += probs[j];
                    if (rand < cumulative_prob) {
                        next_id = j;
                        break;
                    }
                }
                
                context_ids.push(next_id);
                generated_ids.push(next_id);
            }
            ui.generatedOutput.textContent = prompt_text + tokenizer.decode(generated_ids);
            ui.generateBtn.disabled = false;
            ui.trainBtn.disabled = false;
        }

        // --- Привязка событий ---
        ui.trainBtn.addEventListener('click', trainingLoop);
        ui.generateBtn.addEventListener('click', generate);

    </script>
</body>
</html>